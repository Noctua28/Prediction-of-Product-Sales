{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa3dbe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aharo\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import joblib\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d4dddb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the contents of our \"best-models.joblib\" file into a variable called \"loaded_joblib\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loaded_joblib \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/aharo/OneDrive/Documents/GitHub/Prediction-of-Product-Sales/Data/best-models.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\pickle.py:1537\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\pickle.py:1579\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1578\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1579\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "# Load the contents of our \"best-models.joblib\" file into a variable called \"loaded_joblib\"\n",
    "loaded_joblib = joblib.load(\"C:/Users/aharo/OneDrive/Documents/GitHub/Prediction-of-Product-Sales/Data/best-models.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed69a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each object from the loaded_joblib dictionary as a separate variable\n",
    "X_train = loaded_joblib['X_train']\n",
    "X_test = loaded_joblib['X_test']\n",
    "y_train = loaded_joblib['y_train']\n",
    "y_test = loaded_joblib['y_test']\n",
    "preprocessor = loaded_joblib['preprocessor']\n",
    "lr = loaded_joblib['LinearRegression']\n",
    "rf = loaded_joblib['RandomForestRegressor']\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\"\"\"\n",
    "    output_features = []\n",
    "\n",
    "    # Loop through all transformers\n",
    "    for name, trans, columns in column_transformer.transformers_:\n",
    "        if trans == 'drop':\n",
    "            continue\n",
    "        elif isinstance(trans, Pipeline): \n",
    "            trans = trans.steps[-1][1]\n",
    "        if hasattr(trans, 'get_feature_names_out'):\n",
    "            # If the transformer has a 'get_feature_names_out' method\n",
    "            names = list(trans.get_feature_names_out(columns))\n",
    "            output_features += names\n",
    "        elif hasattr(trans, 'get_feature_names'):\n",
    "            # If the transformer has a 'get_feature_names' method\n",
    "            names = list(trans.get_feature_names(columns))\n",
    "            output_features += names\n",
    "        else:\n",
    "            output_features += columns\n",
    "\n",
    "    return output_features\n",
    "\n",
    "feature_names = get_feature_names(preprocessor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef68f8",
   "metadata": {},
   "source": [
    "# Explaining our tree-based model with shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an X_shap and y_shap variable from your training data\n",
    "X_shap = shap.sample(X_train, 100)\n",
    "y_shap = y_train.loc[X_shap.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess X_shap\n",
    "X_shap_preprocessed = preprocessor.transform(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b60370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert the preprocessed X_shap to DataFrame\n",
    "X_shap_df = pd.DataFrame(X_shap_preprocessed.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model explainer\n",
    "explainer = shap.TreeExplainer(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the shap values for your model\n",
    "shap_values = explainer.shap_values(X_shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959af7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary plot - with plot_type='bar'\n",
    "shap.summary_plot(shap_values, X_shap_df, plot_type=\"bar\", show=False)\n",
    "plt.savefig(\"shap_importance.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a880fe",
   "metadata": {},
   "source": [
    "# Summary Plot - Bar Version\n",
    "\n",
    "This plot represents the average impact of each feature on the model's output. The y-axis shows the names of the features, and the x-axis represents the average absolute SHAP value, a measure of the magnitude of a feature's effect on the output. The larger the SHAP value, the higher the impact of the feature on the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a515df5",
   "metadata": {},
   "source": [
    "# Comparison of Most Important Features: SHAP vs. Feature Importance\n",
    "\n",
    "The SHAP values and Random Forest's feature importance don't completely align, and here's why:\n",
    "\n",
    "1. SHAP values take into account not only the direct impact of a feature on the output but also its interaction with other features. This makes SHAP values a more comprehensive measure of feature importance.\n",
    "\n",
    "\n",
    "\n",
    "2. The Random Forest model rates Item_MRP as the most important feature, while SHAP values rank Outlet_Type_Supermarket Type3 at the top. This could be because traditional feature importance measures like those from a Random Forest may be biased towards variables that have more categories or are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap_df, show=False)\n",
    "plt.savefig(\"shap_importance_dot.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba1b62",
   "metadata": {},
   "source": [
    "# Summary Plot - Dot Version\n",
    "\n",
    "This plot shows the impact of each feature on the model's prediction for individual instances. Each dot represents an instance (or a row) from the dataset. The color represents the feature's value (high in red, low in blue). The position on the x-axis shows whether the effect of that value is associated with a higher or lower prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145fb92b",
   "metadata": {},
   "source": [
    "# Interpretation of the Top 3 Most Important Features\n",
    "\n",
    "\n",
    "1. Outlet_Type_Supermarket Type3: This feature has the most significant impact on sales. If a store is a \"Supermarket Type3\", it tends to be associated with higher sales. Conversely, if a store is not of this type, it is likely to have lower sales.\n",
    "\n",
    "\n",
    "\n",
    "2. Item_MRP: This is the price of the product. More expensive items (Item_MRP high, shown in red) are associated with higher sales, while cheaper items (low Item_MRP, shown in blue) tend to have lower sales.\n",
    "\n",
    "\n",
    "\n",
    "3. Outlet_Type_Grocery Store: If an outlet is a grocery store, it is likely to have lower sales. If it's not a grocery store, the sales are likely to be higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d39bd2",
   "metadata": {},
   "source": [
    "# Local Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6bdfec",
   "metadata": {},
   "source": [
    "## LIME Tabular Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lime\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aad68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the X_shap_df DataFrame from the provided CSV file\n",
    "X_shap_df = pd.read_csv(\"C:\\\\Users\\\\aharo\\\\OneDrive\\\\Documents\\\\GitHub\\\\Prediction-of-Product-Sales\\\\X_shap_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instances with low and high predicted sales\n",
    "low_sales_instance = X_shap_df.iloc[0]\n",
    "high_sales_instance = X_shap_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the instances\n",
    "print(\"Low sales instance:\")\n",
    "print(low_sales_instance)\n",
    "print(\"\\nHigh sales instance:\")\n",
    "print(high_sales_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model explainer\n",
    "explainer = shap.TreeExplainer(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP values for these instances\n",
    "shap_values_low = explainer.shap_values(low_sales_instance.values.reshape(1, -1))\n",
    "shap_values_high = explainer.shap_values(high_sales_instance.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f8dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the SHAP Individual Force Plots\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values_low, low_sales_instance, matplotlib=True, show=False)\n",
    "plt.title(\"SHAP Force Plot - Low Sales Instance\")\n",
    "plt.savefig(\"shap_force_plot_low.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values_high, high_sales_instance, matplotlib=True, show=False)\n",
    "plt.title(\"SHAP Force Plot - High Sales Instance\")\n",
    "plt.savefig(\"shap_force_plot_high.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_encoded = encoder.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "# Combine the encoded categorical variables with numerical variables\n",
    "X_train_processed = np.hstack((X_train_encoded, X_train.drop(categorical_cols, axis=1)))\n",
    "\n",
    "# Create a StandardScaler for numerical variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(categorical_cols, axis=1))\n",
    "\n",
    "# Combine the scaled numerical variables with encoded categorical variables\n",
    "X_train_processed = np.hstack((X_train_encoded, X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbcdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME explainer\n",
    "explainer_lime = LimeTabularExplainer(X_train_processed, \n",
    "                                      feature_names=list(encoder.get_feature_names_out(categorical_cols)) + X_train.drop(categorical_cols, axis=1).columns.tolist(),\n",
    "                                      class_names=['Sales'], \n",
    "                                      verbose=True, \n",
    "                                      mode='regression',\n",
    "                                      discretize_continuous=False)  # Disable discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function for the rf model\n",
    "def predict_fn(x):\n",
    "    return rf.predict(x)\n",
    "\n",
    "# Generate LIME explanation for the low sales instance\n",
    "explanation_low = explainer_lime.explain_instance(low_sales_instance.values, predict_fn)\n",
    "\n",
    "# Generate LIME explanation for the high sales instance\n",
    "explanation_high = explainer_lime.explain_instance(high_sales_instance.values, predict_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
